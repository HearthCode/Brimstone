<?xml version="1.0" encoding="utf-8"?>
<topic id="f230a982-28b6-4fd1-b0ce-c3decd883ab4" revisionNumber="1">
  <developerWalkthroughDocument
    xmlns="http://ddue.schemas.microsoft.com/authoring/2003/5"
    xmlns:xlink="http://www.w3.org/1999/xlink">

    <summary>
      <para>This walkthrough explains how to benchmark a single build of Brimstone.</para>
    </summary>

    <introduction>
      <para>These instructions are for Visual Studio on Windows but can be adapted for Mono/Linux.</para>
      <autoOutline lead="In this section:"/>
    </introduction>

    <prerequisites>
      <content>
        <para>
          The <legacyBold>BrimstoneProfiler</legacyBold> repository contains the tools required to benchmark Brimstone applications. You must have a clone of this repository present on your local machine to run benchmarks.
        </para>
      </content>
    </prerequisites>

    <!-- One or more procedure or section with procedure -->
    <procedure>
      <title>To benchmark a single build of Brimstone</title>
      <steps class="ordered">
        <step>
          <content>
            <para>
              Clone the <externalLink>
                <linkText>BrimstoneProfiler</linkText>
                <linkUri>https://github.com/HearthSim/BrimstoneProfiler</linkUri>
                <linkTarget>_blank</linkTarget>
              </externalLink> repository.
            </para>
          </content>
        </step>
        <step>
          <content>
            <para>
              In the <legacyBold>References</legacyBold> section of the <legacyBold>Benchmarks</legacyBold> project, modify the Brimstone reference to point to the build of Brimstone you wish to benchmark. Once you have done this, build the solution.
            </para>
            <alert class="important">
              <para>
                Always build the solution in Release configuration and always reference a Release build of Brimstone.dll.
              </para>
            </alert>
          </content>
        </step>
        <step>
          <content>
            <para>
              Open a command prompt from which to run the benchmarks and navigate to the folder containing the compiled <codeInline>benchmarks.exe</codeInline> tool.
            </para>
            <alert class="important">
              <para>
                Always run <codeInline>benchmarks.exe</codeInline> from the command prompt to ensure accurate results. Running via Visual Studio - even with debugging disabled - starts a host process for the application which will affect the results.
              </para>
            </alert>
          </content>
        </step>
        <step>
          <content>
            <para>
              To run all of the benchmarks with all optimizations enabled, type <codeInline>benchmarks</codeInline> and press Enter. The benchmarks may take several minutes to complete. The output window will show the current progress.
            </para>
            <alert class="important">
              <para>
                Always run benchmarks on a machine with low CPU utilization. Use <legacyBold>Task Manager</legacyBold> to check the current CPU usage on your machine before running benchmarks.
              </para>
              <para>
                Brimstone's published test results are performed with 6-8% background CPU utilization.
              </para>
            </alert>
            <alert class="important">
              <para>
                The first time you run the benchmarks after building, you may experience slower than expected results. This is because the .NET CLR performs JIT compilation on the first run. For more accurate results, run the benchmarks a second time after compiling.
              </para>
            </alert>
          </content>
        </step>
        <step>
          <content>
            <para>
              When the benchmarks have finished running, the output can be found in CSV format in <codeInline>benchmarks.csv</codeInline> in the working folder.
            </para>
          </content>
        </step>
      </steps>
    </procedure>

    <section address="filters">
      <title>To run a selected subset of benchmarks</title>
      <content>
        <para>
          The short test names (those shown in square brackets at the start of each benchmark run) can be filtered on to run a subset of benchmarks. Use the <codeInline>--filter</codeInline> argument with a regular expression to specify a filter, for example:
        </para>
        <code>benchmarks --filter=Arcane.*BFS</code>
        <para>This will cause only the Arcane Missiles breadth-first search tests to run.</para>
      </content>
    </section>

    <section address="settings">
      <title>To run the benchmarks with different settings</title>
      <content>
        <para>
          By default, all optimizations are enabled. To disable one or more optimizations, use the <codeInline>--unset</codeInline> argument with a comma-separated list of settings to disable, for example:
        </para>
        <code>benchmarks --unset=ParallelClone,ZoneCaching</code>
        <para>This will run the benchmarks with parallel cloning and zone caching disabled.</para>
        <alert class="tip">
          <para>
            For a full list of available settings, see <codeEntityReference qualifyHint="true">T:Brimstone.Settings</codeEntityReference>.
          </para>
        </alert>
      </content>
    </section>

    <section address="sets">
      <title>To run benchmarks multiple times with different settings for each run</title>
      <content>
        <para>
          You can specify the <codeInline>--unset</codeInline> parameter multiple times. This will cause each test to run once for each specification, with the selected optimizations disabled. For example:
        </para>
        <code>benchmarks --unset=ParallelClone --unset=ParallelClone,ZoneCaching</code>
        <para>
          This will run each benchmark twice - once with parallel cloning disabled, and once with parallel cloning and zone caching disabled.
        </para>
        <alert class="tip">
          <para>
            To make one of the benchmark sets run with all optimizations enabled, use <codeInline>--unset</codeInline> with no arguments as one of the sets.
          </para>
        </alert>
      </content>
    </section>

    <section address="timeout">
      <title>To set a timeout on benchmark runs</title>
      <content>
        <para>
          You can specify a timeout after which a benchmark will give up with the <codeInline>--timeout</codeInline> parameter. Specify the timeout in milliseconds.
        </para>
        <para>
          Timeouts are disabled by default.
        </para>
        <alert class="caution">
          <para>Setting a timeout creates a background thread to monitor elapsed time and creates an 8-12% negative impact on benchmark performance results. Only use a timeout when you suspect a test is malfunctioning and don't want the benchmark to hang indefinitely.</para>
        </alert>
      </content>
    </section>

    <section address="charting">
      <title>To import benchmarks as an Excel chart</title>
      <content>
        <alert class="note">
          <para>This instructions are for Excel 2016 but should work all versions from Excel 2010 and later.</para>
        </alert>
        <list class="ordered">
          <listItem>
            <para>
              Open Excel and drag <codeInline>benchmarks.csv</codeInline> into it.
            </para>
          </listItem>
          <listItem>
            <para>
              Drag a box around the table including the header but excluding the build line, and press <legacyBold>CTRL+T</legacyBold> or choose <legacyBold>Insert -> Table</legacyBold> from the ribbon bar. Tick <legacyBold>My table has headers</legacyBold> and click OK.
            </para>
            <mediaLink>
              <caption>Excel Benchmarks Insert Table</caption>
              <image xlink:href="ExcelBenchmarksInsertTable"/>
            </mediaLink>
          </listItem>
          <listItem>
            <para>
              Click <legacyBold>Insert -> Recommended Charts</legacyBold> from the ribbon bar and choose the desired chart type. For unrelated benchmarks, <legacyBold>Clustered Column</legacyBold> is generally the best option. If the benchmarks are related, a <legacyBold>Line</legacyBold> chart shows performance improvement and degradation across each test.
            </para>
            <mediaLink>
              <caption>Excel Benchmarks Insert Chart</caption>
              <image xlink:href="ExcelBenchmarksInsertChart"/>
            </mediaLink>
            <alert class="tip">
              <para>
                You can easily style the chart by selecting <legacyBold>Design</legacyBold> from the ribbon and clicking on one of the pre-defined chart styles.
              </para>
            </alert>
            <mediaLink>
              <caption>Excel Benchmarks Style Chart</caption>
              <image xlink:href="ExcelBenchmarksStyleChart"/>
            </mediaLink>
          </listItem>
        </list>
      </content>
    </section>

    <section address="new">
      <title>To create new benchmarks</title>
      <content>
      </content>
    </section>

    <relatedTopics>
      <link xlink:href="4b0b00d6-f9a1-4eae-b880-892eb0d513fb" />
      <link xlink:href="c5beb99b-5b2f-4287-b2e8-c787a10399eb" />
      <link xlink:href="8d25a5f6-350d-4ebb-9a3b-1cb6a60cf573" />
      <codeEntityReference qualifyHint="true">T:Brimstone.Settings</codeEntityReference>
      <externalLink>
        <linkText>BrimstoneProfiler repository homepage</linkText>
        <linkUri>https://github.com/HearthSim/BrimstoneProfiler</linkUri>
        <linkTarget>_blank</linkTarget>
      </externalLink>
    </relatedTopics>
  </developerWalkthroughDocument>
</topic>
